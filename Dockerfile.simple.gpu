## Service-specific GPU simple Dockerfile (transformer)
FROM nvidia/cuda:12.4.1-cudnn-runtime-ubuntu22.04
ARG PYTHON_VERSION=3.11
ENV PIP_NO_CACHE_DIR=1 PYTHONDONTWRITEBYTECODE=1 PYTHONUNBUFFERED=1 APP_HOME=/app PATH="/opt/venv/bin:$PATH" \
    NVIDIA_VISIBLE_DEVICES=all NVIDIA_DRIVER_CAPABILITIES=compute,utility PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
WORKDIR ${APP_HOME}
RUN apt-get update && apt-get install -y --no-install-recommends python${PYTHON_VERSION} python${PYTHON_VERSION}-venv python3-pip build-essential git curl ca-certificates && \
    update-alternatives --install /usr/bin/python python /usr/bin/python${PYTHON_VERSION} 1 && python -m venv /opt/venv && \
    /opt/venv/bin/pip install --upgrade pip wheel setuptools && rm -rf /var/lib/apt/lists/*
COPY requirements*.txt ./
COPY . /tmp_ctx
RUN if [ -f /tmp_ctx/pyproject.toml ]; then cp /tmp_ctx/pyproject.toml ./; fi \
 && if ls /tmp_ctx/poetry.lock* 1>/dev/null 2>&1; then cp /tmp_ctx/poetry.lock* ./; fi \
 && rm -rf /tmp_ctx
RUN if [ -f requirements.txt ]; then /opt/venv/bin/pip install -r requirements.txt; fi && \
    if [ -f requirements.prod.txt ]; then /opt/venv/bin/pip install -r requirements.prod.txt; fi
COPY src ./src
ENV PYTHONPATH=${APP_HOME}/src:${APP_HOME} SERVICE_PORT=8000
ENTRYPOINT ["/bin/bash","-c"]
CMD ["python -c 'import torch,os;print(\"CUDA=\",torch.cuda.is_available());' && tail -f /dev/null"]
HEALTHCHECK --interval=120s --timeout=25s --retries=2 CMD python -c "import torch,sys; sys.exit(0 if torch.cuda.is_available() else 1)" || exit 1
